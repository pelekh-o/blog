+++
author = "Oleh P"
title = "Моніторимо OpenAI API із Splunk"
date = "2023-06-27"
description = "Дізнайтеся, як ефективно відстежувати запити OpenAI API за допомогою Splunk"
tags = [
    "open ai",
    "splunk",
    "monitoring"
]
categories = [
    "Monitoring"
]
draft = false
image = "img/cover.jpeg"
+++
[GitHub Repository](https://github.com/pelekh-o/openai-splunk-monitoring/)

OpenAI API - це потужний інструмент, який дозволяє розробникам інтегрувати найсучасніші можливості обробки природної мови у свої програми. Оскільки використання OpenAI API зростає, з різних причин стає важливим моніторинг та відстеження викликів API. У цій статті ми розглянемо, чому моніторинг викликів OpenAI API є важливим і як ви можете використовувати Splunk, провідну платформу для аналізу та моніторингу даних, для ефективного виконання цього завдання.

## Навіщо потрібен моніторинг запитів OpenAI API?

Моніторинг API запитів дозволяє вам отримати уявлення про те, як ваш додаток взаємодіє з OpenAI API. Аналізуючи шаблони і тенденції використання, ви можете оптимізувати запити до API, точно налаштувати параметри і підвищити загальну продуктивність і ефективність.


## Splunk для моніторингу OpenAI API

За допомогою Splunk ви можете збирати, індексувати та візуалізувати дані з різних джерел, включаючи логи API, показники продуктивності та розрахунки витрат. Використовуючи потужні функції Splunk, такі як інформаційні панелі, сповіщення та звіти, ви можете приймати рішення на основі даних і забезпечувати оптимальне використання OpenAI API.

У наступних розділах я розповім вам про процес налаштування моніторингу OpenAI API за допомогою Splunk, включаючи кроки конфігурації, розрахунок вартості, створення інформаційної панелі та використання методу мавпячих латок.

Давайте поринемо в роботу!

## Початок роботи 

_Примітка: Не забудьте звернутися до оригінального файлу readme з [openai-splunk-monitoring GitHub Repo](https://github.com/pelekh-o/openai-splunk-monitoring/) для отримання повних інструкцій та деталей коду._

_Приклади коду та інструкції, надані лише для ілюстративних цілей. Завжди переглядайте і адаптуйте їх відповідно до ваших конкретних вимог і практик безпеки._

### Крок 1: Налаштування Splunk HEC
- Створіть новий індекс `open_ai`.
- Налаштуйте новий HEC: `Налаштування -> Вхідні дані -> Колектор подій HTTP -> + Додати новий`.
- Задайте ім'я, наприклад, `open_ai`.
- Виберіть тип джерела `_json` та індекс за замовчуванням - `open_ai`.
- Перегляньте конфігурації.
    ![](img/splunk_hec_review.png)
- Скопіюйте значення вашого токена.
- Надішліть.

### Крок 2: Створення таблиці пошуку
Створіть таблицю пошуку, використовуючи наданий файл `openai_prices.csv`.
- Перейдіть до `Налаштування -> Пошуки` і натисніть `+ Додати новий` в розділі `Файли таблиць пошуку`.
- Завантажте файл `openai_prices.csv` і збережіть його.
- Змініть права доступу з `Private` на Global або App.
- Тепер поверніться до Lookups і додайте нове `Lookup definition`.
- Ім'я: `openai_prices`.
- Виберіть файл, який був завантажений раніше `openai_prices.csv`.
- Встановіть прапорець `Додаткові опції` та `WILDCARD(модель)` у полі `Тип відповідності`.
- Збережіть.

### Крок 3: Налаштуйте ваш код
- Встановіть ваші змінні оточення 
    - `SPLUNK_HEC_URL` (наприклад, https://localhost:8088/services/collector)
    - `SPLUNK_HEC_TOKEN` (з [Крок 1: Налаштування Splunk HEC](#Крок-1-Налаштування-Splunk-HEC))
    - `OPENAI_API_KEY` (отримайте його тут: https://platform.openai.com/account/api-keys)
- Додайте файл `openai_splunk_monitor.py` зі сховища [openai-splunk-monitoring](https://github.com/pelekh-o/openai-splunk-monitoring) git-репозиторію.
- Додайте наступні рядки до вашого коду:
```python
from openai_splunk_monitor import init_monitor
init_monitor()
```
### Крок 4: Додаємо дашборд
- Щоб візуалізувати зібрані дані, ми створимо власний дашборд в Splunk's Dashboard Studio. Просто імпортуйте код з `dashboard.json` у ваш екземпляр Splunk

![](img/dashboard.png)


## Розрахунок витрат
Розрахунок витрачених коштів виконується в Splunk за допомогою пошуку, створеного в [Крок 2: Створення пошуку](#Крок-2-Створення-пошуку).

Ось приклад SPL для розрахунку витрат на модель:
```
index="open_ai"
| rename response.usage.* as *, request.model as model
| lookup openai_prices model OUTPUTNEW price_prompt, price_competition
| eval price_prompt = mvindex(price_prompt, 0)
| eval price_competition = mvindex(price_competition, 0)
| eval request_price = (price_prompt * prompt_tokens + price_competition * completion_tokens)/1000
| stats sum(total_tokens), sum(request_price) by model
| rename sum(*) as *
```

![](img/spl_costs_out.png)

## Monkey Patching
Для збору метрик відгуку та інших важливих даних ми використовуємо "мавпячі латки" (monkey patching). Мавпячі латки - це техніка, яка дозволяє нам динамічно змінювати поведінку виклику завершення під час виконання. Застосовуючи цю техніку, ми можемо збирати необхідну інформацію і відправляти її в Splunk для подальшого аналізу.